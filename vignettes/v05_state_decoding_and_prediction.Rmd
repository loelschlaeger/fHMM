---
title: "State decoding and prediction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{State decoding and prediction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: ref.bib
link-citations: true
---

<!-- 
Assignee: Rouven (theory part), Lennart (application part)
Purpose: definition of Viterbi algorithm, application in fHMM
--> 

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.dim = c(10,6),
  out.width = "80%",
  fig.align = 'center',
  fig.path = 'figs/'
)
library(fHMM)
```

This vignette^[This vignette was build using R `r paste(R.Version()[6:7], collapse = ".")` with the {fHMM} `r utils::packageVersion("fHMM")` package.] introduces the Viterbi algorithm for state decoding. The decoded state sequence in combination with the estimated model parameters can be used for forecasting.

## State decoding usig the Viterbi algorithm

For financial markets, it is of special interest to infer the underlying (hidden) states in order to gain insight about the actual market situation. Decoding a full time series $S_1, \ldots, S_T$ is called *global decoding*. Hereby, we aim to find the most likely trajectory of hidden states under the estimated model. 
Global decoding can be accomplished by using the so-called Viterbi algorithm which is a recursive scheme enabling to find the global maximum without being confronted with huge computational costs. To this end, we follow @zuc16 and define
$$\zeta_{1i} = Pr(S_1 = i, X_1 = x_1) = \delta_i p_i(x_1)$$ 
for $i = 1, \ldots, N$ and for the following $t = 2, \ldots, T$
$$\zeta_{ti} = \operatorname*{max}_{s_1, \ldots, s_{t-1}} Pr(S_{t-1} = s_{t-1}, S_t = i, X_t = x_t).$$ 
Then, the trajectory of most likely states $i_1, \ldots, i_T$ can be calculated recursively from
$$i_T = \operatorname*{argmax}_{i = 1, \ldots, N} \zeta_{Ti}$$ and for the following $t = T-1, \ldots, 1$ from
$$i_t = \operatorname*{argmax}_{i = 1, \ldots, N} (\zeta_{ti} \gamma_{i, i_{t+1}}).$$
Transferring the state decoding to HHMMs is straightforward: at first the coarse-scale state process must be decoded. Afterwards, by using this information the fine-scale state process can be decoded, see @ada19.

## Application

We revisit the DAX application of the vignette on model estimation, where we fitted the following model:

```{r data preparation, cache=TRUE}
controls <- list(
  states = 3,
  sdds   = "t",
  data   = list(file        = system.file("extdata", "dax.csv", package = "fHMM"),
                date_column = "Date",
                data_column = "Close",
                from        = "2000-01-01",
                to          = "2022-01-01",
                logreturns  = TRUE),
  fit    = list("runs" = 100)
)
controls <- set_controls(controls)
data <- prepare_data(controls)
model <- fit_model(data, seed = 1, verbose = FALSE)
```

## References
