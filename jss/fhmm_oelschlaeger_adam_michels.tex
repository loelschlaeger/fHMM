\documentclass[article,shortnames]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}

%% additional packages
\usepackage{orcidlink,amssymb,amsmath}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}
\raggedbottom

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}



%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Lennart Oelschl\"ager~\orcidlink{0000-0001-5421-9313}\\Bielefeld University \And Timo Adam~\orcidlink{0000-0001-9079-3259}\\University of St Andrews\And Rouven Michels \\Bielefeld University}
\Plainauthor{Lennart Oelschl\"ager, Timo Adam, Rouven Michels}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{\pkg{fHMM}: Hidden Markov Models for Financial Time Series in \proglang{R}}
\Plaintitle{fHMM: Hidden Markov Models for Financial Time Series in R}
\Shorttitle{\pkg{fHMM}}

\Abstract{
%% Intro to HMMs
Hidden Markov models constitute a versatile class of statistical models for time series that are driven by hidden states. In financial applications, the hidden states can often be linked to market regimes such as bearish and bullish markets or recessions and periods of economics growth. To give an example, when the market is in a nervous state, corresponding stock returns often follow some distribution with relatively high variance, whereas calm periods are often characterized by a different distribution with relatively smaller variance. Hidden Markov models can be used to explicitly model the distribution of the observations conditional on the hidden states and the transitions between states, and thus help us to draw a comprehensive picture of market behavior.
%% Intro to the package
While various implementations of hidden Markov models are available, an \proglang{R} package that is tailored to financial applications is still lacking. In this paper, we introduce the \proglang{R} package \pkg{fHMM}, which provides various tools for applying hidden Markov models to financial time series. It contains functions for fitting hidden Markov models to data, conducting simulation experiments, and decoding the underlying state sequence. Furthermore, functions for model checking, model selection, and state prediction are provided. In addition to basic hidden Markov models, hierarchical hidden Markov models are implemented, which can be used to jointly model multiple data streams that were observed at different temporal resolutions. The aim of the \pkg{fHMM} package is to give \proglang{R} users with an interest in financial applications access to hidden Markov models and their extensions.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{hidden Markov models, hierarchical hidden Markov models, regime switching, financial time series, decoding market behavior, \proglang{R}}
\Plainkeywords{hidden Markov models, regime switching, financial time series, decoding market behavior, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Lennart Oelschl\"ager\\
  Department of Business Administration and Economics\\
  Bielefeld University\\
  Postfach 10 01 31, Germany\\
  E-mail: \email{lennart.oelschlaeger@uni-bielefeld.de}\\ \\
  Timo Adam \\
  School of Mathematics and Statistics\\
  University of St Andrews\\
  The Observatory, Buchanan Gardens, St Andrews KY16 9LZ, UK\\
  E-mail: \email{ta59@st-andrews.ac.uk}\\ \\
  Rouven Michels \\
  Department of Business Administration and Economics\\
  Bielefeld University\\
  Postfach 10 01 31, Germany\\
  E-mail: \email{r.michels@uni-bielefeld.de}
}

\begin{document}

%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, \fct{} and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section{Introduction}
\label{sec:intro} %% Timo 

%% Intro to HMMs
In recent years, hidden Markov models (HMMs) have emerged as a popular tool for modeling time series that are subject to state-switching over time \citep{zuc16}. In their basic form, HMMs comprise an observed state-dependent process that is driven by a hidden state process, the latter of which is typically modeled using a discrete-time, finite-state Markov chain. In financial applications, the states of the underlying Markov chain can often be linked to market regimes such as bearish and bullish markets or recessions and periods of economics growths. To give an example, when the market is in a nervous state, corresponding stock returns often follow some distribution with relatively high variance, whereas when the market is in a clam state, another distribution with relatively smaller variance is active. By their dependence structure, HMMs naturally account for such disparate patterns and thus allow us to infer hidden market regimes and their underlying dynamics from financial time series.

%% Literature review
Over the last decades, HMMs have become increasingly popular in finance. In various studies, they have been applied to model business cycles \citep{kim98, gre00}, to derive stylized facts of stock returns \citep{bul06, nys15a}, and to model energy prices conditional on market regimes \citep{lan18, ada19c, ada22}, to name but a few examples. \cite{lih17} used HMMs to model volatility in the Standard and Poor's 500 index to investigate the conjecture that stock returns exhibit negative correlation with volatility. \cite{ngu18} used HMMs to predict closing prices to derive an optimal trading strategy, which was shown to outperform the conventional buy-and-hold strategy, whereas \cite{bul11, nys15a, nys18} have shown that HMMs prove useful in asset allocation and portfolio optimization applications. All these examples demonstrate that HMMs constitute a versatile class of statistical models for time series that naturally accounts for the state-switching patterns often found in financial data.

%% Software overview
In \proglang{R} \citep{r21}, various implementations of HMMs are available. For general purposes, the packages \pkg{hmm} \citep{him10}, \pkg{depmixS4} \citep{vis10}, and \pkg{msm} \citep{jac11} are frequently used. In addition, a wide range of special-purpose packages is available, for example \pkg{moveHMM} \citep{mic16} and \pkg{momentuHMM} \citep{mcc18} for modeling ecological time series, \pkg{hsmm} \citep{bul10} and \pkg{mhsmm} \citep{oco11} for hidden semi-Markov models, \pkg{hmm.discnp} \citep{tur14} and \pkg{countHMM} \citep{ada19b} for modeling count data, and \pkg{LMest} \citep{bar17} for longitudinal data. In \proglang{Python}, the library \pkg{hmmlearn} \citep{leb22} can be used. In \proglang{MATLAB} \citep{matlab}, the \pkg{Hidden Markov Model} toolbox \citep{che22} can be used. In \proglang{Stata} \citep{stata}, HMMs are implemented in the \fct{mswitch} function. Yet, an \proglang{R} package that is tailored to financial applications is still lacking.

%% Intro to the package
In this paper, we introduce the \proglang{R} package \pkg{fHMM} \citep{oel22}, which aims at complementing the above mentioned collection of implementations by making HMMs accessible to \proglang{R} users with an interest in financial time series. The package functionality can be classified into functions for data preparation, model estimation, and model evaluation, which are illustrated in the flowchart displayed in Figure \ref{fig:flowchart}. 
\begin{figure}[t!]
  \includegraphics{flowchart.png}
  \caption{Flowchart. The main functions of the \pkg{fHMM} package are visualized using rectangles, while objects are illustrated as ovals.}
  \label{fig:flowchart}
\end{figure}
Functions for data preparation include a convenient interface to Yahoo Finance (https://www.finance.yahoo.com) that allows users to download stock market data. The model is estimated in a maximum likelihood framework, where the likelihood is evaluated using the forward algorithm, which is implemented in \proglang{C++} and parallelized for fast and efficient computation. Functions for model evaluation include pseudo-residual analyses and the computation of model selection criteria. In addition to basic HMMs, the package also implements hierarchical HMMs (HHMMs). HHMMs \citep{oel21} constitute an extension that improves the model's capability of distinguishing between short- and long-term trends in the data and allows us to jointly model multiple data streams that were collected at different temporal resolutions, such as monthly trade volumes and daily stock returns \citep{ada20}. 

%% Outline of the paper
The paper is structured as follows: In Section \ref{sec:model_definition}, we introduce HMMs and HHMMs, where we focus on their dependence structure and the underlying model assumptions. In Sections \ref{sec:model_specification}--\ref{sec:model_selection}, we illustrate a typical workflow using the \pkg{fHMM} package, where we explain how to specify a model, how to download, prepare, and simulate data, how to fit a model, how to decode the hidden states, how to use a fitted model for state forecasting, how to check the goodness of fit, and how to perform model selection. Each section begins with some theoretical background, which is followed by illustrating examples using stock market data from the Deutscher Aktienindex (DAX) and the Volkswagen Group (VW) as well as simulated data. Each of these sections is complemented by code chunks, which cannot only be used to replicate the examples given in this paper but also serve as a starting point for \proglang{R} users with an interest in financial time series who want to apply HMMs to their own data. Section \ref{sec:conclusion} concludes and gives an outlook of anticipated, future extensions of the \pkg{fHMM} package.

%% -- Manuscript ---------------------------------------------------------------

%% - In principle "as usual" again.
%% - When using equations (e.g., {equation}, {eqnarray}, {align}, etc.
%%   avoid empty lines before and after the equation (which would signal a new
%%   paragraph.
%% - When describing longer chunks of code that are _not_ meant for execution
%%   (e.g., a function synopsis or list of arguments), the environment {Code}
%%   is recommended. Alternatively, a plain {verbatim} can also be used.
%%   (For executed code see the next section.)
%% - Tables are placed at the top of the page
%%   (\verb|[t!]|), centered (\verb|\centering|), with a caption below the table,
%%   column headers and captions in sentence style, and if possible avoiding
%%   vertical lines.
%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.
%% - Please make sure that all code is properly spaced, e.g., using
%%   \code{y = a + b * x} and \emph{not} \code{y=a+b*x}.
%% - JSS prefers when the second line of code is indented by two spaces.

\section{Model definition} \label{sec:model_definition} %% Rouven

Hidden Markov models (HMMs) constitute a modeling framework for time series where a sequence of observations is assumed to depend on a hidden state process. The peculiarity is that, instead of the observation process, the state process cannot be directly observed. However, the hidden states comprise information about the environment the model is applied on. The hidden state process and the observed state-dependent process are connected as follows: we assume that for each point in time $t = 1, \ldots, T$, an underlying process $(S_t)_{t = 1, \ldots, T}$ is in one of $N$ possible states. Then, depending on the active state $S_t \in \{ 1, \ldots, N \}$, the observation $X_t$ from the state-dependent process $(X_t)_{t = 1, \ldots, T}$ is assumed to be generated by the corresponding state-dependent distribution $f^{(S_t)}$. We assume $(S_t)_t$ to be Markovian, i.e., the active state at time $t$ only depends on the previous state at time $t-1$. Henceforth, the state process is identified by its initial distribution $\delta = (\delta_i), \delta_i = \Pr(S_1 = i), i = 1, \ldots, N$, and its transition probability matrix (t.p.m.) $\Gamma = (\gamma_{ij}), \gamma_{ij} = \Pr(S_{t} = j \mid S_{t-1}=i), i,j = 1, \ldots, N, t = 2, \ldots, T$. Furthermore, $(X_t)_{t = 1, \ldots, T}$ satisfies the conditional independence assumption, i.e., the observation $X_t$ depends on $S_t$, but is independent from previous observations or states.

When modeling financial time series, the different states can serve as proxies for the current market situation, e.g., calm and nervous. Even though these moods cannot be directly observed, price changes or trading volumes (which can be assumed to depend on the current mood of the market) are observable. Thereby, using an underlying Markov process, we can infer which mood is active at any point in time and how the different moods alternate. Depending on the current mood, a price change is generated by a different distribution. These distributions characterize the moods in terms of expected return and volatility. For example, we can explicitly model price changes at time $t$ by different normal distributions whose mean and variance depend on the current state, $S_t$.

Following \cite{zuc16}, we assume that the initial distribution $\delta$ equals the stationary distribution $\pi$, where $\pi = \pi \Gamma$, i.e., the stationary and henceforth the initial distribution is determined by $\Gamma$.\footnote{A note on the existence of a stationary distribution: If the Markov process is irreducible, it has a unique distribution, which is the solution to the equation system $\pi = \pi \Gamma$. If, additionally, the Markov process is aperiodic, its state distribution converges to the stationary distribution, see \cite{nor97}. Irreducibility and aperiodicity are usually satisfied in practice.} This is reasonable from a practical point of view: On the one hand, the hidden state process has been evolving for some time before we start to observe it and hence can be assumed to be stationary. On the other hand, setting $\delta=\pi$ reduces the number of parameters that need to be estimated, which is convenient from a computational perspective.

HHMMs constitute a flexible extension of basic HMMs that can be used to jointly model multiple data observed on two different time scales \citep{oel21}. The two time series, one on a coarser and one on a finer scale, differ in the number of observations, e.g., monthly observations on the coarser scale and daily observations on the finer scale. Following the concept of HMMs, we can model both state-dependent time series jointly. First, we treat the time series on the coarser scale as stemming from an ordinary HMM, which we refer to as the coarse-scale HMM: At each time point $t$ of the coarse-scale time space $\{1,\dots,T\}$, an underlying process $(S_t)_t$ selects one state from the coarse-scale state space $\{1,\dots,N\}$. We refer to $(S_t)_t$ as the hidden coarse-scale state process. Depending on which state is active at time $t$, one of $N$ possible distributions $f^{(1)},\dots,f^{(N)}$ realizes the observation $X_t$. The process $(X_t)_t$ is called the observed coarse-scale state-dependent process. The processes $(S_t)_t$ and $(X_t)_t$ have the same properties as before, namely $(S_t)_t$ is a first-order Markov process and $(X_t)_t$ satisfies the conditional independence assumption. This dependence structure is visualized in the upper part of Figure \ref{fig:hhmm}.

For the fine-scale time series, the observed data is split into $T$ distinct chunks, each of them having a correspondence to the $t$-th coarse-scale time point. The hierarchical structure arises naturally: For each chunk, we model the corresponding data points via the fine-scale HMM that is selected by the hidden coarse-scale state $S_t = i$. Thus, each fine-scale HMM consists of two stochastic processes: The hidden fine-scale process $(S^*_{t,t^*})_{t^*}$ selecting states from $\{1,\dots,N^*\}$, the fine-scale state space, for each time point $t^*$ in $\{1,\dots,T^*\}$, the fine-scale time space, and the observed fine-scale process $(X^*_{t,t^*})_{t^*}$, whose observations are assumed to depend on one of $N^*$ possible distributions $f^{*(i,1)},\dots,f^{*(i,N^*)}$, chosen depending on the active fine-scale state. By construction, each fine-scale HMM contains an own t.p.m.\ $\Gamma^{*(i)}$, initial distribution $\delta^{*(i)}$, stationary distribution $\pi^{*(i)}$, and state-dependent distributions $f^{*(i,1)},\dots,f^{*(i,N^*)}$. Similar to the coarse-scale HMM, the hidden fine-scale process is Markovian and satisfies the conditional independence assumption. In contrast, the observed fine-scale process has exclusive dependence on the active state of the hidden fine-scale process. This dependence structure is visualized in Figure \ref{fig:hhmm}.

\begin{figure}
  \centering
  \includegraphics{hhmm.png}
  \caption{Dependence structure of an HHMM. The dependence structure of a basic HMM is visualized in the upper part.}
  \label{fig:hhmm}
\end{figure}

\section{Model specification} \label{sec:model_specification} %% Lennart

In the \pkg{fHMM} package, models are specified by a named list of controls that is passed to the \fct{set\_controls} function. This usually constitutes the first step when using the package, see Figure \ref{fig:flowchart}. The function checks the specifications and returns an \class{fHMM\_controls} object, which stores all settings and thereby provides the information required for other functionalities. In the following, we demonstrate three example specifications that should help the user to tailor an HMM to their need. The examples are continued in the following sections. All possible specifications are documented in detail on the function's help page, which can be accessed from the \proglang{R} console via \code{help(set_controls, package = "fHMM")}.

\paragraph{Example 1: DAX.} We fit a 3-state HMM to the closing prices of the DAX \citep{jan92}. Assume that the data are available in the working directory as file \code{"dax.csv"}. Such data can be obtained directly from Yahoo Finance via the convenience function \fct{download\_data}, see Section \ref{sec:data_management}.

The following code chunk sets the number \code{states = 3} of hidden states. Any number greater than or equal to 2 is possible. Next, \code{sdds = "t"} specifies state-dependent t-distributions, which provide a popular choice for modeling log-returns \citep{pla08}. Alternatively, \code{sdds = "gamma"} specifies Gamma distributions, which are useful for model trading volumes, see \cite{ada20}. Additionally, log-normal distributions are available via \code{sdds = "lnorm"}. The \code{data} entry sets the path to the data file (\code{file = "dax.csv"}), the file's column that contains the dates (\code{date_column = "Date"}), and the data (\code{date_column = "Close"}). The specification \code{logreturns = TRUE} transforms the data to log-returns.

%
\begin{Schunk}
\begin{Sinput}
R> contr_dax <- list(
+    states = 3,
+    sdds   = "t",
+    data   = list(file        = "dax.csv",
+                  date_column = "Date",
+                  data_column = "Close",
+                  logreturns  = TRUE)
+  )
\end{Sinput}
\end{Schunk}
%

Passing this list to the \fct{set\_controls} function returns an object of class \class{fHMM\_controls}, which contains the specifications and default settings.

%
\begin{Schunk}
\begin{Sinput}
R> contr_dax <- set_controls(contr_dax)
R> class(contr_dax)
\end{Sinput}
\begin{Soutput}
[1] "fHMM_controls"
\end{Soutput}
\end{Schunk}
%

\paragraph{Example 2: Simulation.} If the \code{data} entry is not specified, data is simulated according to the model specification. Simulation typically serves to assess the properties of estimation algorithms either for research or in a bootstrap-like fashion, as can be seen for example in \cite{oel19}. The following code chunk specifies a 2-state HMM with state-dependent Gamma distributions, where the expected values\footnote{Expected value and standard deviation of a Gamma distribution are obtained by means of a parameter transformation.} for state 1 and 2 are fixed to \code{1} and \code{2}, respectively. The model is fitted to 200 data points (\code{horizon = 200}) simulated according to this specification based on \code{runs = 50} randomly initialized numerical optimization runs of the model's likelihood function. Printing the \class{fHMM\_controls} object summarizes the model specification:

%
\begin{Schunk}
\begin{Sinput}
R> contr_sim <- list(
+    states  = 2,
+    sdds    = "gamma(mu = 1|2)",
+    horizon = 200,
+    fit     = list(runs = 50)
+  )
R> (contr_sim <- set_controls(contr_sim))
\end{Sinput}
\begin{Soutput}
fHMM controls:
* hierarchy: FALSE 
* data type: simulated 
* number of states: 2 
* sdds: gamma(mu = 1|2) 
* number of runs: 50  
\end{Soutput}
\end{Schunk}
%

\paragraph{Example 3: Multiple data streams.} An HHMM can be specified by adding \code{hierarchy = TRUE} to the controls. The following is a specification for the DAX data on the fine scale and the VW data on the coarse scale (both data sets are contained in the \pkg{fHMM} package): 

%
\begin{Schunk}
\begin{Sinput}
R> file <- c(system.file("extdata", "dax.csv", package = "fHMM"),
+            system.file("extdata", "vw.csv", package = "fHMM"))
R> contr_hhmm <- list(
+    hierarchy = TRUE,
+    states    = c(2,2),
+    sdds      = c("t(df = 1)", "t(df = 1)"),
+    period    = "m",
+    data      = list(file = file,
+                     date_column = c("Date","Date"),
+                     data_column = c("Close","Close"),
+                     from = "2015-01-01",
+                     to = "2020-01-01",
+                     logreturns = c(TRUE,TRUE),
+                     merge = function(x) mean(x))
+  )
R> contr_hhmm <- set_controls(contr_hhmm)
\end{Sinput}
\end{Schunk}
%

The line \code{states = c(2, 2)} specifies \code{2} coarse-scale and \code{2} fine-scale states, respectively. State-dependent t-distributions are used, where the degrees of freedom are fixed to \code{1} on both time scales (setting \code{df = Inf} is possible and results in state-dependent normal distributions). Via \code{period = "m"}, we specify a monthly fine-scale time horizon. Alternatives are \code{"w"}, \code{"q"}, and \code{"y"} for weekly, quarterly, and yearly time horizons, respectively. The observation period is restricted to five years via \code{from = "2015-01-01"} and \code{to = "2020-01-01"}. With \code{logreturns = c(TRUE,TRUE)}, we ensure that the data on both time scales are transformed to log-returns. If the coarse-scale data have a finer temporal resolution than defined by \code{period}, the data can be merged by specifying a function via the \code{merge} argument. In this example, the file \code{"dax.vw"} contains daily closing prices. Since we specified \code{merge = function(x) mean(x)}, the monthly average closing prices are used as coarse-scale observations.

\section{Data management} \label{sec:data_management} %% Lennart

Empirical data for modeling must be provided as a comma-separated values (.csv) file. Its path must be specified in \fct{set\_controls}, see the previous section. The package includes the convenience function \fct{download\_data} for downloading daily stock market data directly from Yahoo Finance in the required format. The function call is \code{download\_data(symbol, from, to, file)}, where

- \code{symbol} is the stock's symbol that has to match the official symbol on Yahoo Finance,

- \code{from} and \code{to} define the desired time interval (in the format \code{"YYYY-MM-DD"}),

- \code{file} is the name of the saved file. Per default, it is saved in the current working directory under the name \code{<symbol>.csv}.

For example, the 21st century data of the DAX can be downloaded via the following line:

%
\begin{Schunk}
\begin{Sinput}
R> download_data(symbol = "^GDAXI", from = "2001-01-01", to = Sys.Date())
\end{Sinput}
\end{Schunk}
%

\paragraph{Example 1: DAX (cont.).} Recall the control specification for the 3-state HMM DAX model from the previous section. The \fct{prepare\_data} function prepares the data based on the specifications and returns an \class{fHMM\_data} object. This object can then be passed to the \fct{fit\_model} function for model fitting in the next step, see Section \ref{sec:model_estimation}. The \fct{summary} method provides an overview of the data.

%
\begin{Schunk}
\begin{Sinput}
R> data_dax <- prepare_data(contr_dax)
R> summary(data_dax)
\end{Sinput}
\begin{Soutput}
Summary of fHMM empirical data
* number of observations: 8823 
* data source: dax.csv 
* date column: Date 
* log returns: TRUE 
\end{Soutput}
\end{Schunk}
%

In addition, the data can be visualized via the \fct{plot} method. To facilitate interpretation, historical events with a potential influence on the time series can be highlighted as follows:

%
\begin{Schunk}
\begin{Sinput}
R> events <- fHMM_events(
+    list(
+      dates = c("2001-09-11", "2008-09-15", "2020-01-27"),
+      labels = c("9/11 terrorist attack", "Bankruptcy of Lehman Brothers", 
+                 "First COVID-19 case in Germany")
+      )
+    )
R> plot(data_dax, events = events)
\end{Sinput}
\end{Schunk}
\includegraphics{fhmm_oelschlaeger_adam_michels-dax-ts}
%

\paragraph{Example 2: Simulation (cont.).} As mentioned in the previous section, if the \code{data} argument in the model's controls is unspecified, data is simulated according to the model specification. True model parameters can be specified by defining an \class{fHMM\_parameters}-object via the \fct{fHMM\_parameters} function and passing it to \fct{prepare\_data}, for example:

%
\begin{Schunk}
\begin{Sinput}
R> pars <- fHMM_parameters(
+    controls = contr_sim, 
+    Gamma = matrix(c(0.9,0.2,0.1,0.8), nrow = 2), 
+    sigmas = c(0.1,0.5)
+  )
R> data_sim <- prepare_data(contr_sim, true_parameters = pars, seed = 1)
\end{Sinput}
\end{Schunk}
%

The plot of the simulated time series shows the state persistence (induced by $\gamma_{11} = 0.9$ and $\gamma_{22} = 0.8$) and the different standard deviations ($\sigma_1 = 0.1$ and $\sigma = 0.5$) of the state-dependent Gamma distributions. Remember that the expected values were set to $\mu_1 = 1$ and $\mu_2 = 2$.

%
\begin{Schunk}
\begin{Sinput}
R> plot(data_sim)
\end{Sinput}
\end{Schunk}
\includegraphics{fhmm_oelschlaeger_adam_michels-sim-data-ts}
%

\paragraph{Example 3: Multiple data streams (cont.).} Data preparation for the HHMM can be done analogously:

%
\begin{Schunk}
\begin{Sinput}
R> data_hhmm <- prepare_data(contr_hhmm)
\end{Sinput}
\end{Schunk}
%

\section{Model estimation} \label{sec:model_estimation} %% Timo + Lennart

The \pkg{fHMM} package implements the maximum likelihood method for model estimation. In the following, the likelihood function of an HHMM is derived, the non-hierarchical case can be deduced. We also discuss challenges related to the numerical maximization and subsequently estimate the three running example models.

An HHMM can be treated as an HMM with two conditionally independent data streams; the coarse-scale observations on the one hand and the corresponding chunk of fine-scale observations connected to a fine-scale HMM on the other hand. To derive the likelihood of an HHMM, we start by computing the likelihood of each chunk of fine-scale observations being generated by each fine-scale HMM. 

To fit the $i$-th fine-scale HMM, with model parameters $\theta^{*(i)}=(\delta^{*(i)}, \Gamma^{*(i)},(f^{*(i,k)})_k)$ to the $t$-th chunk of fine-scale observations, which is denoted by $(X_{t,t^*})_{t^*}$, we consider the fine-scale forward probabilities 
\begin{align*}
\alpha^{*(i)}_{k,t^*}=f^{*(i)}(X^*_{t,1},\dots,X^*_{t,t^*}, S^*_{t,t^*}=k),
\end{align*}
where $t^*=1,\dots,T^*$ and $k=1,\dots,N^*$. Using the fine-scale forward probabilities, the fine-scale likelihoods can be obtained from the law of total probability as
\begin{align*}
\mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{t,t^*})_{t^*})=\sum_{k=1}^{N^*}\alpha^{*(i)}_{k,T^*}.
\end{align*}
The forward probabilities can be calculated recursively as
\begin{align*}
\alpha^{*(i)}_{k,1} &= \delta^{*(i)}_k f^{*(i,k)}(X^*_{t,1}), \\
\alpha^{*(i)}_{k,t^*} &= f^{*(i,k)}(X^*_{t,t^*})\sum_{j=1}^{N^*}\gamma^{*(i)}_{jk}\alpha^{*(i)}_{j,t^*-1}, \quad t^*=2,\dots,T^*.
\end{align*}

The transition from the likelihood function of an HMM to the likelihood function of an HHMM is straightforward: Consider the coarse-scale forward probabilities
\begin{align*}
\alpha_{i,t}=f(X_1,\dots,X_t,(X^*_{1,t^*})_{t^*},\dots,(X^*_{t,t^*})_{t^*}, S_t=i),
\end{align*}
where $t=1,\dots,T$ and $i=1,\dots,N$. The likelihood function of the HHMM results as
\begin{align*}
\mathcal{L}^\text{HHMM}(\theta,(\theta^{*(i)})_i\mid (X_t)_t,((X^*_{t,t^*})_{t^*})_t)=\sum_{i=1}^{N}\alpha_{i,T}.
\end{align*}
The coarse-scale forward probabilities can be calculated similarly:
\begin{align*}
\alpha_{i,1} &= \delta_i \mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{1,t^*})_{t^*})f^{(i)}(X_1), \\
\alpha_{i,t} &= \mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{t,t^*})_{t^*}) f^{(i)}(X_t)\sum_{j=1}^{N}\gamma_{ji}\alpha_{j,t-1}, \quad t=2,\dots,T.
\end{align*}

To account for parameter constraints associated with the transition probabilities (and potentially the parameters of the state-dependent distributions), we use parameter transformations. To ensure that the entries of the t.p.m.s fulfill non-negativity and the unity condition, we estimate unconstrained values $(\eta_{ij})_{i\neq j}$ for the non-diagonal entries of $\Gamma$ and derive the probabilities using the multinomial logit link
\begin{align*}
\gamma_{ij}=\frac{\exp(\eta_{ij})}{1+\sum_{k\neq i}\exp(\eta_{ik})},~i\neq j
\end{align*}
rather than estimating the probabilities $(\gamma_{ij})_{i,j}$ directly. The diagonal entries result from the unity condition as
\begin{align*}
\gamma_{ii}=1-\sum_{j\neq i}\gamma_{ij}.
\end{align*}
Furthermore, variances are strictly positive, which can be achieved by applying an exponential transformation to the unconstrained estimator.

Two more technical difficulties arise: First, we often face numerical under- or overflow, which can be addressed by maximizing the logarithm of the likelihood and incorporating constants in a conducive way, see \cite{oel21} for the details. Second, as the likelihood is maximized with respect to a relatively large number of parameters, the obtained maximum can be a local rather than the global one. To avoid this problem, it is recommended to run the maximization multiple times from different, possibly randomly selected starting points, and to choose the model that corresponds to the highest likelihood \citep{zuc16}. For efficient initialization, the \pkg{fHMM} package uses the first and second data moments as a basis for the initial guesses.

\paragraph{Example 1: DAX (cont.).} In Section \ref{sec:data_management}, we defined the \class{fHMM\_data} object \code{data\_dax}. This object can be directly passed to the \fct{fit\_model} function that numerically maximizes the model's (log-) likelihood function:\footnote{The numerical maximization runs can be parallelized by setting the function's \code{ncluster} argument to a value greater than 1.}

%
\begin{Schunk}
\begin{Sinput}
R> dax_model_3t <- fit_model(data_dax)
\end{Sinput}
\end{Schunk}
%

The estimated model is saved in the \pkg{fHMM} package and can be accessed via:

%
\begin{Schunk}
\begin{Sinput}
R> data("dax_model_3t", package = "fHMM")
\end{Sinput}
\end{Schunk}
%

The \fct{coef} method returns a data frame of the estimated model coefficients along with 1-\code{alpha} confidence intervals (\code{alpha = 0.05} being the default) obtained via the inverse Fisher information (\code{lb} stands for lower- and \code{ub} for upper-bound of the intervals, respectively):

%
\begin{Schunk}
\begin{Sinput}
R> coef(dax_model_3t, alpha = 0.05)
\end{Sinput}
\begin{Soutput}
                     lb      estimate           ub
Gamma_2.1  1.393745e-02  2.170056e-02 3.357222e-02
Gamma_3.1  1.710420e-06  1.696596e-06 1.671225e-06
Gamma_1.2  1.659146e-02  2.641008e-02 4.179228e-02
Gamma_3.2  9.359401e-03  1.740175e-02 3.213059e-02
Gamma_1.3  1.258535e-08  1.246159e-08 1.226657e-08
Gamma_2.3  2.789877e-03  5.145960e-03 9.431251e-03
mu_1       9.610235e-04  1.268712e-03 1.576400e-03
mu_2      -7.955275e-04 -2.517499e-04 2.920278e-04
mu_3      -3.723796e-03 -1.673649e-03 3.764982e-04
sigma_1    5.332119e-03  5.774343e-03 6.253244e-03
sigma_2    1.269075e-02  1.323801e-02 1.380887e-02
sigma_3    2.329677e-02  2.562622e-02 2.818860e-02
df_1       3.964154e+00  5.272157e+00 7.011747e+00
df_2       7.592272e+04  7.592547e+04 7.592821e+04
df_3       5.501298e+00  1.064107e+01 2.058285e+01
\end{Soutput}
\end{Schunk}
%

Adding \code{plot\_type = "sdds"} to the \fct{plot} method visualizes the estimated state-dependent distributions. The effect of local optima in the HMM likelihood can be visualized by adding \code{plot\_type = "ll"}, which plots the log-likelihood values in the different optimization runs (the best run is marked in red).

%
\begin{Schunk}
\begin{Sinput}
R> par(mfrow = c(1,2))
R> plot(dax_model_3t, plot_type = c("ll","sdds"))
\end{Sinput}
\end{Schunk}
\includegraphics{fhmm_oelschlaeger_adam_michels-dax-sdds-ll}
%

\paragraph{Example 2: Simulation (cont.).} Fitting an HMM to the simulated data is analogue via the \fct{fit\_model} function. The estimated model \code{sim\_model\_2gamma} is also saved in \pkg{fHMM}: 

%
\begin{Schunk}
\begin{Sinput}
R> data("sim_model_2gamma", package = "fHMM")
\end{Sinput}
\end{Schunk}
%

The \fct{summary} method gives an overview of the estimated model. In the simulated case, we can compare the estimates to the true model coefficients:

%
\begin{Schunk}
\begin{Sinput}
R> summary(sim_model_2gamma)
\end{Sinput}
\begin{Soutput}
Summary of fHMM model

  simulated hierarchy        LL      AIC      BIC
1      TRUE     FALSE -192.9676 393.9353 407.1286

State-dependent distributions:
gamma(mu = 1|2) 

Estimates:
               lb estimate     ub true
Gamma_2.1 0.06475  0.17804 0.4039  0.2
Gamma_1.2 0.03052  0.07781 0.1844  0.1
sigma_1   0.44079  0.49962 0.5663  0.5
sigma_2   0.70108  0.92279 1.2146  1.0
\end{Soutput}
\end{Schunk}
%

\paragraph{Example 3: Multiple data streams (cont.).}

In the hierarchical case, we can visualize the estimated state-dependent distributions on both the coarse-scale and the fine-scale layer:

%
\begin{Schunk}
\begin{Sinput}
R> # dax_vw_model <- fit_model(data_hhmm)
R> data("dax_vw_model", package = "fHMM")
R> plot(dax_vw_model, plot_type = "sdds")
\end{Sinput}
\end{Schunk}
\includegraphics{fhmm_oelschlaeger_adam_michels-hhmm-sdds}
%

\section{State decoding and prediciton} \label{sec:state_decoding_and_prediction} %% Rouven + Lennart

For financial markets, it is of special interest to infer the underlying (hidden) states in order to gain insight about the actual market situation and for prediction. The Viterbi algorithm \citep{for73} is a recursive scheme that enables to find the most likely trajectory of hidden states under the estimated HMM. To this end, we follow \cite{zuc16} and define
\begin{align*}
  \zeta_{1i} &= \Pr(S_1 = i, X_1 = x_1) = \delta_i p_i(x_1) \\
  \zeta_{ti} &= \operatorname*{max}_{s_1, \ldots, s_{t-1}} \Pr(S_{t-1} = s_{t-1}, S_t = i, X_t = x_t)
\end{align*}
for $i = 1, \ldots, N$ (the index for the states) and $t = 2, \ldots, T$ (the index of time). Then, the trajectory of most likely states $i_1, \ldots, i_T$ can be calculated recursively backwards from
\begin{align*}
  i_T &= \operatorname*{argmax}_{i = 1, \ldots, N} \zeta_{Ti} \\
  i_t &= \operatorname*{argmax}_{i = 1, \ldots, N} (\zeta_{ti} \gamma_{i, i_{t+1}}), \quad t = T-1, \ldots, 1.
\end{align*}

Transferring the state decoding to HHMMs is straightforward via decoding the coarse-scale states first and afterwards, by using this information, decoding the fine-scale state process, see \cite{ada19}.

In the following, we introduce the \fct{decode\_states} function for state decoding and the \fct{predict} method for forecasting. As all of the functionalities of the \pkg{fHMM} package presented in the remainder of this paper are completely analogue for the hierarchical and the simulated case, respectively, we will focus our attention on example 1 and invite the reader to apply the methods to example 2 and 3 on their own. 

\paragraph{Example 1: DAX (cont.).} The underlying states of the 3-state HMM for the DAX can be decoded via the \fct{decode\_states} function, which updates an \class{fHMM\_model} object. 

%
\begin{Schunk}
\begin{Sinput}
R> dax_model_3t <- decode_states(dax_model_3t)
\end{Sinput}
\end{Schunk}
%

The state sequence is saved as argument \code{dax_model_3t$decoding}:

%
\begin{Schunk}
\begin{Sinput}
R> table(dax_model_3t$decoding)
\end{Sinput}
\begin{Soutput}
   1    2    3 
2177 2753  695 
\end{Soutput}
\end{Schunk}
%

The decoded time series can then be visualized using the \fct{plot} method:\footnote{Notice that the model is invariant to permutations of the state labels. The \pkg{fHMM} package provides the option to switch labels after state decoding via the \fct{reorder\_states} function. For example, \code{reorder\_states(dax\_model\_3t, 3:1)} reverses the order.}

%
\begin{Schunk}
\begin{Sinput}
R> plot(dax_model_3t)
\end{Sinput}
\end{Schunk}
\includegraphics{fhmm_oelschlaeger_adam_michels-dax-dec-ts}
%

After decoded the underlying states, we use the estimated transition probabilities to compute the state probabilities of the subsequent observations. Based on these probabilities and in combination with the estimated state-dependent distributions, the subsequent observations can be predicted, compare \cite{zuc16}:

%
\begin{Schunk}
\begin{Sinput}
R> predict(dax_model_3t, ahead = 5)
\end{Sinput}
\begin{Soutput}
  state_1 state_2 state_3       lb estimate      ub
1 0.02170 0.97315 0.00515 -0.02190 -0.00023 0.02145
2 0.04225 0.94769 0.01006 -0.02179 -0.00020 0.02138
3 0.06170 0.92354 0.01477 -0.02168 -0.00018 0.02132
4 0.08011 0.90063 0.01926 -0.02158 -0.00016 0.02126
5 0.09754 0.87890 0.02356 -0.02148 -0.00014 0.02121
\end{Soutput}
\end{Schunk}
%

Columns 1 to 3 show the state probabilities for the next \code{ahead = 5} trading days. The values in columns 4 to 6 (the bounds of the 95\%-confidence intervals and the point predictions) are log-returns, which obviously can be transformed to index values or relative returns.

\section{Model checking} \label{sec:model_checking} %% Timo + Lennart

Checking whether a fitted model describes the data well is an essential part of any modeling process. In the HMM setting, this is typically done by analyzing the so-called pseudo-residuals \citep{zuc16}. Since the observations are modeled by different distributions (depending on the active state), they have to be transformed on a common scale, which can be done as follows: If the observation $X_t$ has the invertible distribution function $F_{X_t}$, then $Z_t=\Phi^{-1}(F_{X_t} (X_t))$ is standard normally distributed, where $\Phi$ denotes the cumulative distribution function of the standard normal distribution. The observations are modeled well if the pseudo-residuals $(Z_t)_t$ are approximately standard normally distributed and exhibit no autocorrelation. In the hierarchical case, we first decode the coarse-scale state process using the Viterbi algorithm. Subsequently, we assign each coarse-scale observation its distribution function under the fitted model and perform the transformation described above. Using the Viterbi-decoded coarse-scale states, we then treat the fine-scale observations analogously.

\paragraph{Example 1: DAX (cont.).}

Via the \fct{compute\_residuals} function, pseudo-residuals can be computed (provided that the states have been decoded beforehand). The function updates the \code{dax_model_3t} object in the following line:

%
\begin{Schunk}
\begin{Sinput}
R> dax_model_3t <- compute_residuals(dax_model_3t)
\end{Sinput}
\end{Schunk}
%

The normality and independence of the pseudo-residuals can be verified visually:

%
\begin{Schunk}
\begin{Sinput}
R> plot(dax_model_3t, plot_type = "pr")
\end{Sinput}
\end{Schunk}
\includegraphics{fhmm_oelschlaeger_adam_michels-dax-res}
%

Alternatively, the residuals can be extracted from the model object via the \fct{residuals} method for normality tests, for example a Jarque-Bera test \citep{jar87}:\footnote{Here, the test is unable to reject the null hypothesis that the data is normally distributed.}

%
\begin{Schunk}
\begin{Sinput}
R> tseries::jarque.bera.test(residuals(dax_model_3t))
\end{Sinput}
\begin{Soutput}
	Jarque Bera Test

data:  residuals(dax_model_3t)
X-squared = 2.6542, df = 2, p-value = 0.2652
\end{Soutput}
\end{Schunk}
%

\section{Model selection} \label{sec:model_selection} %% Timo + Lennart

Model selection involves the choice of a family for the state-dependent distributions and the selection of the number of states. Common model selection tools are information criteria, such as the Akaike information criterion (AIC) \citep{aka74} or the Bayesian information criterion (BIC) \citep{sch78}. They are defined as
\begin{align*}
\text{AIC} &= - 2 \log \mathcal{L}^\text{(H)HMM} + 2 p; \\
\text{BIC} &= - 2 \log \mathcal{L}^\text{(H)HMM} + \log(T) p,
\end{align*}
where $p$ denotes the number of model parameters and $T$ is the number of observations. Both criteria aim at finding a compromise between model fit and model complexity, where a model with a lower value is to be preferred. For an in-depth discussion of pitfalls, practical challenges, and pragmatic solutions regarding model selection, we refer to \cite{poh17}. The \pkg{fHMM} package provides the \fct{compare\_models} function that takes (arbitrarily many) \class{fHMM\_model} objects as input and returns a matrix of the number of parameters, the log-likelihood value, the AIC, and the BIC. 

\paragraph{Example 1: DAX (cont.).} We compare our 3-state HMM with state-dependent t-distribu- tions fitted to the Dax data to an HMM with 2 states and normal state-dependent distributions. The competing model was estimated using the same data and can be accessed as object \code{dax_model_2n}. In this example, both AIC and BIC clearly prefer the more complex model:

%
\begin{Schunk}
\begin{Sinput}
R> data("dax_model_2n", package = "fHMM")
R> compare_models(dax_model_2n, dax_model_3t)
\end{Sinput}
\begin{Soutput}
             parameters log-likelihood       AIC       BIC
dax_model_2n          6       16681.98 -33351.96 -33312.15
dax_model_3t         15       16913.33 -33796.65 -33697.13
\end{Soutput}
\end{Schunk}
%

%% -- Summary/conclusions/discussion -------------------------------------------

\section{Conclusions} \label{sec:conclusion} % Timo + Rouven + Lennart

The \pkg{fHMM} package aims at making HMMs accessible to \proglang{R} users with an interest in financial time series. It contains functions to download, prepare, and simulate data, to fit models, to decode the hidden states, to use a fitted model for state forecasting, to check the goodness of fit, and to perform model selection. The \pkg{fHMM} package has a user-friendly design: All model specifications are centralized in a list of controls, four different package objects can be seamlessly passed between functions, and its usage follows a clear workflow (see Figure \ref{fig:flowchart}). In this paper, we illustrated a typical workflow using three illustrating examples (an application to stock market data from the DAX and VW as well as a model fitted to simulated data) that serves as a starting point for \proglang{R} users who want to apply HMMs and their extensions to their own data.

Current limitations of the \pkg{fHMM} package include (1) the confined set of available state-dependent distributions for the observations, (2) the restriction to a discrete state space, (3) the restriction to a discretized time dimension, (4) the limitation of a maximum number of two hierarchies in HHMMs, and (5) the need to specify the number of hidden states in advance of the model estimation. We plan to overcome these limitations and invite the community to suggest further features that we can implement in future package versions.

%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

The results presented in this paper were obtained using
\proglang{R}~4.1.0 with the
\pkg{fHMM}~1.0.2 package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at \url{https://CRAN.R-project.org/}.


% \section*{Acknowledgments}

%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - Journal titles should not be abbreviated and in title case.
%% - DOIs should be included where available.
%% - Software should be properly cited as well.

\bibliography{ref}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".
% 
% \newpage
% 
% \begin{appendix}
% 
% \section{Installation} \label{app:installation}
% 
% \end{appendix}
% 
%% -----------------------------------------------------------------------------


\end{document}
