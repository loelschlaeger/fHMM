<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Model definition • fHMM</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model definition">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">fHMM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.4.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/fHMM.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/v01_model_definition.html">Model definition</a></li>
    <li><a class="dropdown-item" href="../articles/v02_controls.html">Controls</a></li>
    <li><a class="dropdown-item" href="../articles/v03_data_management.html">Data management</a></li>
    <li><a class="dropdown-item" href="../articles/v04_model_estimation.html">Model estimation</a></li>
    <li><a class="dropdown-item" href="../articles/v05_state_decoding_and_prediction.html">State decoding and prediction</a></li>
    <li><a class="dropdown-item" href="../articles/v06_model_checking.html">Model checking</a></li>
    <li><a class="dropdown-item" href="../articles/v07_model_selection.html">Model selection</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/loelschlaeger/fHMM/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Model definition</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/fHMM/blob/master/vignettes/v01_model_definition.Rmd" class="external-link"><code>vignettes/v01_model_definition.Rmd</code></a></small>
      <div class="d-none name"><code>v01_model_definition.Rmd</code></div>
    </div>

    
    
<p>The <a href="https://loelschlaeger.de/fHMM/">fHMM</a> package is an implementation of the hidden
Markov model with a focus on applications to financial time series data.
This vignette<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;This vignette was build using R 4.4.1 with the
&lt;a href="https://loelschlaeger.de/fHMM/"&gt;fHMM&lt;/a&gt; 1.4.0 package.&lt;/p&gt;'><sup>1</sup></a> introduces the model and its hierarchical
extension. It closely follows <span class="citation">Oelschläger and
Adam (<a href="#ref-oel21">2021</a>)</span>.</p>
<div class="section level2">
<h2 id="the-hidden-markov-model">The Hidden Markov Model<a class="anchor" aria-label="anchor" href="#the-hidden-markov-model"></a>
</h2>
<p>Hidden Markov models (HMMs) are a modeling framework for time series
data where a sequence of observation is assumed to depend on a latent
state process. The peculiarity is that, instead of the observation
process, the state process cannot be directly observed. However, the
latent states comprise information about the environment the model is
applied on.</p>
<p>The connection between hidden state process and observed
state-dependent process arises by the following: Let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
be the number of possible states. We assume that for each point in time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">t = 1, \ldots, T</annotation></semantics></math>,
an underlying process
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow></msub><annotation encoding="application/x-tex">(S_t)_{t = 1, \ldots, T}</annotation></semantics></math>
selects one of those
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
states. Then, depending on the active state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>t</mi></msub><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">S_t \in \{ 1, \ldots, N \}</annotation></semantics></math>,
the observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>t</mi></msub><annotation encoding="application/x-tex">X_t</annotation></semantics></math>
from the state-dependent process
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow></msub><annotation encoding="application/x-tex">(X_t)_{t = 1, \ldots, T}</annotation></semantics></math>
is generated by one of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
distributions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>,</mo><mi>…</mi><mo>,</mo><msup><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mi>.</mi></mrow><annotation encoding="application/x-tex">f^{(1)},\dots,f^{(N)}.</annotation></semantics></math><a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;The package includes the normal- and t-distribution for
modeling log-returns and the gamma distribution for modeling absolute
quantities like trading volume. Additionally, log-normal distributions
can be specified.&lt;/p&gt;"><sup>2</sup></a></p>
<p>Furthermore, we assume
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(S_t)_t</annotation></semantics></math>
to be Markovian, i.e. we assume that the actual state only depends on
the previous state. Henceforth, we can identify the process by its
initial distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math>
and its transition probability matrix (t.p.m.)
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Γ</mi><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math>.
Moreover, by construction, we force the process
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>t</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi></mrow></msub><annotation encoding="application/x-tex">(X_t)_{t = 1, \ldots, T}</annotation></semantics></math>
to satisfy the conditional independence assumption, i.e. the actual
observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>t</mi></msub><annotation encoding="application/x-tex">X_t</annotation></semantics></math>
depends on the current state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mi>t</mi></msub><annotation encoding="application/x-tex">S_t</annotation></semantics></math>,
but does not depend on previous observations or states at all. The
following graphic visualizes the dependence structure:</p>
<div class="float">
<img src="hmm.png" style="width:80.0%" alt="Dependence structure of the HMM."><div class="figcaption">Dependence structure of the HMM.</div>
</div>
<p>Referring to financial data, the different states can serve as
proxies for the actual market situation, e.g. calm or nervous. Even
though these moods cannot be observed directly, price changes or trading
volumes, which clearly depend on the current mood of the market, can be
observed. Thereby, using an underlying Markov process, we can detect
which mood is active at any point in time and how the different moods
alternate. Depending on the current mood, a price change is generated by
a different distribution. These distributions characterize the moods in
terms of expected return and volatility.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;For example, we can model price changes at time point
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;annotation encoding="application/x-tex"&gt;t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;
to be generated by different normal distributions whose mean and
volatility depend on
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;msub&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/msub&gt;&lt;annotation encoding="application/x-tex"&gt;S_t&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;.&lt;/p&gt;'><sup>3</sup></a></p>
<p>Following <span class="citation">Zucchini, MacDonald, and Langrock
(<a href="#ref-zuc16">2016</a>)</span>, we assume that the initial
distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>δ</mi><annotation encoding="application/x-tex">\delta</annotation></semantics></math>
equals the stationary distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>π</mi><annotation encoding="application/x-tex">\pi</annotation></semantics></math>,
where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo>=</mo><mi>π</mi><mi>Γ</mi></mrow><annotation encoding="application/x-tex">\pi = \pi \Gamma</annotation></semantics></math>,
i.e. the stationary and henceforth the initial distribution is
determined by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Γ</mi><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math>.<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;If the Markov process is irreducible, it has a unique
distribution, which solves
&lt;math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;π&lt;/mi&gt;&lt;mi&gt;Γ&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\pi = \pi \Gamma&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;.
If additionally the Markov process is aperiodic, its state distribution
converges to the stationary distribution, see &lt;span class="citation"&gt;Norris (&lt;a href="#ref-nor97"&gt;1997&lt;/a&gt;)&lt;/span&gt;.
Irreducibility and aperiodicity are usually satisfied assumptions in
reality.&lt;/p&gt;'><sup>4</sup></a> This is
reasonable from a practical point of view: On the one hand, the hidden
state process has been evolving for some time before we start to observe
it and hence can be assumed to be stationary. On the other hand, setting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>=</mo><mi>π</mi></mrow><annotation encoding="application/x-tex">\delta=\pi</annotation></semantics></math>
reduces the number of parameters that need to be estimated, which is
convenient from a computational perspective.</p>
</div>
<div class="section level2">
<h2 id="adding-a-hierarchical-structure">Adding a Hierarchical Structure<a class="anchor" aria-label="anchor" href="#adding-a-hierarchical-structure"></a>
</h2>
<p>The hierarchical hidden Markov model (HMMM) is a flexible extension
of the HMM that can jointly model data observed on two different time
scales. The two time series, one on a coarser and one on a finer scale,
differ in the number of observations, e.g. monthly observations on the
coarser scale and daily or weekly observations on the finer scale.</p>
<p>Following the concept of HMMs, we can model both state-dependent time
series jointly. First, we treat the time series on the coarser scale as
stemming from an ordinary HMM, which we refer to as the coarse-scale
HMM: At each time point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>
of the coarse-scale time space
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>T</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{1,\dots,T\}</annotation></semantics></math>,
an underlying process
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(S_t)_t</annotation></semantics></math>
selects one state from the coarse-scale state space
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{1,\dots,N\}</annotation></semantics></math>.
We call
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(S_t)_t</annotation></semantics></math>
the hidden coarse-scale state process. Depending on which state is
active at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>,
one of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
distributions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>,</mo><mi>…</mi><mo>,</mo><msup><mi>f</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">f^{(1)},\dots,f^{(N)}</annotation></semantics></math>
realizes the observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>t</mi></msub><annotation encoding="application/x-tex">X_t</annotation></semantics></math>.
The process
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(X_t)_t</annotation></semantics></math>
is called the observed coarse-scale state-dependent process. The
processes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(S_t)_t</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(X_t)_t</annotation></semantics></math>
have the same properties as before, namely
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>S</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(S_t)_t</annotation></semantics></math>
is a first-order Markov process and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mi>t</mi></msub><annotation encoding="application/x-tex">(X_t)_t</annotation></semantics></math>
satisfies the conditional independence assumption.</p>
<p>Subsequently, we segment the observations of the fine-scale time
series into
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math>
distinct chunks, each of which contains all data points that correspond
to the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>-th
coarse-scale time point. Assuming that we have
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>T</mi><mo>*</mo></msup><annotation encoding="application/x-tex">T^*</annotation></semantics></math>
fine-scale observations on every coarse-scale time point, we face
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math>
chunks comprising of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>T</mi><mo>*</mo></msup><annotation encoding="application/x-tex">T^*</annotation></semantics></math>
fine-scale observations each.</p>
<p>The hierarchical structure now evinces itself as we model each of the
chunks by one of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
possible fine-scale HMMs. Each of the fine-scale HMMs has its own
t.p.m. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>Γ</mi><mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msup><annotation encoding="application/x-tex">\Gamma^{*(i)}</annotation></semantics></math>,
initial distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>δ</mi><mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msup><annotation encoding="application/x-tex">\delta^{*(i)}</annotation></semantics></math>,
stationary distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>π</mi><mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msup><annotation encoding="application/x-tex">\pi^{*(i)}</annotation></semantics></math>,
and state-dependent distributions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msup><mo>,</mo><mi>…</mi><mo>,</mo><msup><mi>f</mi><mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><msup><mi>N</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">f^{*(i,1)},\dots,f^{*(i,N^*)}</annotation></semantics></math>.
Which fine-scale HMM is selected to explain the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>-th
chunk of fine-scale observations depends on the hidden coarse-scale
state
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mi>t</mi></msub><annotation encoding="application/x-tex">S_t</annotation></semantics></math>.
The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>-th
fine-scale HMM explaining the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>-th
chunk of fine-scale observations consists of the following two
stochastic processes: At each time point
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>t</mi><mo>*</mo></msup><annotation encoding="application/x-tex">t^*</annotation></semantics></math>
of the fine-scale time space
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><msup><mi>T</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{1,\dots,T^*\}</annotation></semantics></math>,
the process
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>S</mi><mrow><mi>t</mi><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub><annotation encoding="application/x-tex">(S^*_{t,t^*})_{t^*}</annotation></semantics></math>
selects one state from the fine-scale state space
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mn>1</mn><mo>,</mo><mi>…</mi><mo>,</mo><msup><mi>N</mi><mo>*</mo></msup><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{1,\dots,N^*\}</annotation></semantics></math>.
We call
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>S</mi><mrow><mi>t</mi><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub><annotation encoding="application/x-tex">(S^*_{t,t^*})_{t^*}</annotation></semantics></math>
the hidden fine-scale state process. Depending on which state is active
at
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>t</mi><mo>*</mo></msup><annotation encoding="application/x-tex">t^*</annotation></semantics></math>,
one of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>N</mi><mo>*</mo></msup><annotation encoding="application/x-tex">N^*</annotation></semantics></math>
distributions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msup><mo>,</mo><mi>…</mi><mo>,</mo><msup><mi>f</mi><mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>i</mi><mo>,</mo><msup><mi>N</mi><mo>*</mo></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">f^{*(i,1)},\dots,f^{*(i,N^*)}</annotation></semantics></math>
realizes the observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>X</mi><mrow><mi>t</mi><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><annotation encoding="application/x-tex">X^*_{t,t^*}</annotation></semantics></math>.
The process
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>X</mi><mrow><mi>t</mi><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub><annotation encoding="application/x-tex">(X^*_{t,t^*})_{t^*}</annotation></semantics></math>
is called the observed fine-scale state-dependent process.</p>
<p>The fine-scale processes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>S</mi><mrow><mn>1</mn><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>S</mi><mrow><mi>T</mi><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub></mrow><annotation encoding="application/x-tex">(S^*_{1,t^*})_{t^*},\dots,(S^*_{T,t^*})_{t^*}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>X</mi><mrow><mn>1</mn><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>X</mi><mrow><mi>T</mi><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub></mrow><annotation encoding="application/x-tex">(X^*_{1,t^*})_{t^*},\dots,(X^*_{T,t^*})_{t^*}</annotation></semantics></math>
satisfy the Markov property and the conditional independence assumption,
respectively, as well. Furthermore, it is assumed that the fine-scale
HMM explaining
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>X</mi><mrow><mi>t</mi><mo>,</mo><msup><mi>t</mi><mo>*</mo></msup></mrow><mo>*</mo></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><msup><mi>t</mi><mo>*</mo></msup></msub><annotation encoding="application/x-tex">(X^*_{t,t^*})_{t^*}</annotation></semantics></math>
only depends on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>S</mi><mi>t</mi></msub><annotation encoding="application/x-tex">S_t</annotation></semantics></math>.
This hierarchical structure is visualized in the following:</p>
<div class="float">
<img src="hhmm.png" style="width:80.0%" alt="Dependence structure of the HHMM."><div class="figcaption">Dependence structure of the HHMM.</div>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-nor97" class="csl-entry">
Norris, J. R. 1997. <span>“Markov Chains.”</span> <em>Cambridge
University Press</em>.
</div>
<div id="ref-oel21" class="csl-entry">
Oelschläger, L., and T. Adam. 2021. <span>“Detecting Bearish and Bullish
Markets in Financial Time Series Using Hierarchical Hidden Markov
Models.”</span> <em>Statistical Modelling</em>. <a href="https://doi.org/10.1177/1471082X211034048" class="external-link">https://doi.org/10.1177/1471082X211034048</a>.
</div>
<div id="ref-zuc16" class="csl-entry">
Zucchini, W., I. L. MacDonald, and R. Langrock. 2016. <span>“Hidden
Markov Models for Time Series: An Introduction Using <span>R</span>, 2nd
Edition.”</span> <em>Chapman and Hall/CRC</em>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://loelschlaeger.de" class="external-link">Lennart Oelschläger</a>, <a href="https://www.uni-bielefeld.de/fakultaeten/wirtschaftswissenschaften/lehrbereiche/statisticalmodelling/" class="external-link">Timo Adam</a>, <a href="https://ekvv.uni-bielefeld.de/pers_publ/publ/PersonDetail.jsp?personId=241029889" class="external-link">Rouven Michels</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
