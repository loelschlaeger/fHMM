<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="fHMM">
<title>Model fitting • fHMM</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Model fitting">
<meta property="og:description" content="fHMM">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">fHMM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.3.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-2">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/data_management.html">Data management</a>
    <a class="dropdown-item" href="../articles/debugging.html">Debugging</a>
    <a class="dropdown-item" href="../articles/introduction.html">Introduction</a>
    <a class="dropdown-item" href="../articles/model_checking.html">Model checking</a>
    <a class="dropdown-item" href="../articles/model_definition.html">Model definition</a>
    <a class="dropdown-item" href="../articles/model_fitting.html">Model fitting</a>
    <a class="dropdown-item" href="../articles/model_results.html">Model results</a>
    <a class="dropdown-item" href="../articles/model_selection.html">Model selection</a>
    <a class="dropdown-item" href="../articles/prediction.html">Prediction</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/loelschlaeger/fHMM/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">
<script src="model_fitting_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Model fitting</h1>
                        <h4 data-toc-skip class="author">Lennart Oelschläger, Timo Adam and Rouven Michels</h4>
            
            <h4 data-toc-skip class="date">2021-12-07</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/loelschlaeger/fHMM/blob/HEAD/vignettes/model_fitting.Rmd" class="external-link"><code>vignettes/model_fitting.Rmd</code></a></small>
      <div class="d-none name"><code>model_fitting.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="likelihood-evaluation-and-numerical-maximization">Likelihood evaluation and numerical maximization<a class="anchor" aria-label="anchor" href="#likelihood-evaluation-and-numerical-maximization"></a>
</h2>
<p>Conceptually, an HHMM can be treated as an HMM with two conditionally independent observations, the coarse-scale observation on the one hand and the corresponding chunk of fine-scale observations connected to a fine-scale HMM on the other hand. To derive the likelihood of an HHMM, we start by stating the likelihood formula for the fine-scale HMMs.</p>
<p>Assume that we want to fit the <span class="math inline">\(i\)</span>-th fine-scale HMM, with model parameters <span class="math inline">\(\theta^{*(i)}=(\delta^{*(i)},\Gamma^{*(i)},(f^{*(i,k)})_k)\)</span>, to the <span class="math inline">\(t\)</span>-th chunk of fine-scale observations, <span class="math inline">\((X_{t,t^*})_{t^*}\)</span>. Consider the so-called fine-scale forward probabilities <span class="math inline">\(\alpha^{*(i)}_{k,t^*}=f^{*(i)}(X^*_{t,1},\dots,X^*_{t,t^*}, S^*_{t,t^*}=k)\)</span>, where <span class="math inline">\(t^*=1,\dots,T^*\)</span> and <span class="math inline">\(k=1,\dots,N^*\)</span>. Obviously, <span class="math display">\[\begin{align*}
\mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{t,t^*})_{t^*})=\sum_{k=1}^{N^*}\alpha^{*(i)}_{k,T^*}.
\end{align*}\]</span> The forward probabilities can be calculated in a recursive way of linear complexity: <span class="math display">\[\begin{align*}
\alpha^{*(i)}_{k,1} = \delta^{*(i)}_k f^{*(i,k)}(X^*_{t,1}) \quad \text{and} \quad
\alpha^{*(i)}_{k,t^*} = f^{*(i,k)}(X^*_{t,t^*})\sum_{j=1}^{N^*}\gamma^{*(i)}_{jk}\alpha^{*(i)}_{j,t^*-1}, \quad t^*=2,\dots,T^*.
\end{align*}\]</span></p>
<p>The transition from the likelihood function of an HMM to the likelihood function of an HHMM is straightforward: Consider the so-called coarse-scale forward probabilities <span class="math inline">\(\alpha_{i,t}=f(X_1,\dots,X_t,(X^*_{1,t^*})_{t^*},\dots,(X^*_{t,t^*})_{t^*}, S_t=i)\)</span>, where <span class="math inline">\(t=1,\dots,T\)</span> and <span class="math inline">\(i=1,\dots,N\)</span>. The likelihood function of the HHMM results as <span class="math display">\[\begin{align*}
\mathcal{L}^\text{HHMM}(\theta,(\theta^{*(i)})_i\mid (X_t)_t,((X^*_{t,t^*})_{t^*})_t)=\sum_{i=1}^{N}\alpha_{i,T}.
\end{align*}\]</span> The coarse-scale forward probabilities can be calculated similarly by applying the recursive scheme <span class="math display">\[\begin{align*}
\alpha_{i,1} &amp;= \delta_i \mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{1,t^*})_{t^*})f^{(i)}(X_1), \\
\alpha_{i,t} &amp;= \mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{t,t^*})_{t^*}) f^{(i)}(X_t)\sum_{j=1}^{N}\gamma_{ji}\alpha_{j,t-1}, \quad t=2,\dots,T.
\end{align*}\]</span></p>
</div>
<div class="section level2">
<h2 id="challenges-in-the-maximization-of-the-likelihood">Challenges in the maximization of the likelihood<a class="anchor" aria-label="anchor" href="#challenges-in-the-maximization-of-the-likelihood"></a>
</h2>
<p>Maximization of the likelihood function is numerically feasible using the Newton-Raphson method. In practice, we often face the technical issues such as numerical under- or overflow, which can be addressed by maximizing the logarithm of the likelihood and incorporating constants in a conducive way. Instead of computing the forward probabilities directly, we consider the logarithmic transformation <span class="math inline">\(\phi^{*(i)}_{k,t^*}=\log[\alpha^{*(i)}_{k,t^*}]\)</span> and <span class="math inline">\(\phi_{i,t}=\log[\alpha_{i,t}]\)</span> thereof (log-forward probabilities). The recursive form described above remains: The fine-scale log-forward probabilities satisfy <span class="math display">\[\begin{align*}
\phi^{*(i)}_{k,1}&amp;=\log[\delta^{*(i)}_k]+\log[f^{*(i,k)}(X^*_{t,1})], \\
\phi^{*(i)}_{k,t^*}&amp;=\log[f^{*(i,k)}(X^*_{t,t^*})]+\log\left[\sum_{j=1}^{N^*} \gamma^{*(i)}_{jk} \exp[ \phi^{*(i)}_{j,t^*-1} -c_{t^*-1}]\right]+c_{t^*-1},
\end{align*}\]</span> where <span class="math inline">\(c_{t^*-1}=\max \{ \phi^{*(i)}_{1,t^*-1},\dots,\phi^{*(i)}_{N^*,t^*-1} \}\)</span> and <span class="math inline">\(t^*=2,\dots,T^*\)</span>. The log-likelihood of a fine-scale HMM results from these variables as <span class="math display">\[\begin{align*}
\log \mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{t,t^*})_{t^*})=\log \left[ \sum_{k=1}^{N^*}\exp[\phi^{*(i)}_{k,T^*}-c_{T^*}]\right]+c_{T^*},
\end{align*}\]</span> where <span class="math inline">\(c_{T^*} = \max\{ \phi^{*(i)}_{1,T^*},\dots,\phi^{*(i)}_{N^*,T^*} \}\)</span>. See Algorithm  in the appendix for pseudo-code of the computation. The coarse-scale log-forward probabilities satisfy <span class="math display">\[\begin{align*}
\phi_{i,1}&amp;=\log[\delta_i]+\log \mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{1,t^*})_{t^*})+\log[f^{(i)}(X_{1})], \\
\phi_{i,t}&amp;=\log \mathcal{L}^\text{HMM}(\theta^{*(i)}\mid (X^*_{t,t^*})_{t^*})+\log[f^{(i)}(X_t)]+\log\left[\sum_{j=1}^{N}\gamma_{ji}\exp[\phi_{j,t-1}-c_{t-1}]\right]+c_{t-1},
\end{align*}\]</span> where <span class="math inline">\(c_{t-1} = \max\{ \phi_{1,t-1},\dots,\phi_{N,t-1} \}\)</span> and <span class="math inline">\(t=2,\dots,T\)</span>. The log-likelihood of the HHMM results from these variables as <span class="math display">\[\begin{align*}
\log \mathcal{L}^\text{HHMM}(\theta,(\theta^{*(i)})_i\mid (X_t)_t,((X^*_{t,t^*})_{t^*})_t)=\log\left[\sum_{i=1}^{N}\exp[\phi_{i,T}-c_{T}]\right]+c_{T},
\end{align*}\]</span> where <span class="math inline">\(c_{T} = \max\{ \phi_{1,T},\dots,\phi_{N,T} \}\)</span>. See Algorithm  in the appendix for a pseudo-code.</p>
<p>Additionally, we have to consider that certain model parameters must satisfy constraints, namely the transition probabilities and potentially parameters of the state-dependent distributions. Using parameter transformations serves the purpose. To ensure that the entries of the t.p.m.s fulfill non-negativity and the unity condition, we use a bijective transformation from the real numbers to the unity interval. Rather than estimating the probabilities <span class="math inline">\((\gamma_{ij})_{i,j}\)</span> directly, we estimate unconstrained values <span class="math inline">\((\eta_{ij})_{i\neq j}\)</span> for the non-diagonal entries of <span class="math inline">\(\Gamma\)</span> and derive the probabilities using the multinomial logit link <span class="math display">\[\begin{align*}
\gamma_{ij}=\frac{\exp[\eta_{ij}]}{1+\sum_{k\neq i}\exp[\eta_{ik}]},~i\neq j.
\end{align*}\]</span> The diagonal entries result from the unity condition <span class="math inline">\(\gamma_{ii}=1-\sum_{j\neq i}\gamma_{ij}\)</span>. Noteworthy, not <span class="math inline">\(N^2\)</span> but <span class="math inline">\(N(N-1)\)</span> parameters have to be estimated for an <span class="math inline">\(N\times N\)</span>-t.p.m. Furthermore, variances are strictly positive, which can be achieved by applying an exponential transformation to the unconstrained estimator. For basic HMMs,  show that identifiability holds when the state-dependent distributions are distinct and the t.p.m. is ergodic and has full rank, conditions that are usually fulfilled in practice. Given that the fine-scale HMMs are distinct, this also holds for HHMMs (for a discussion of identifiability in HHMMs, see ).</p>
<p>A third source of conflicts arises from the fact that the likelihood is maximized with respect to a relatively large number of parameters, which can lead to local maxima apart from the global maximum. Common Newton-Raphson-type optimization routines are unable to distinguish local maxima from the global one. To avoid the trap of ending up at a local maximum, we recommended to run the maximization routine multiple times from different, possibly randomly selected starting points, and to choose the model that corresponds to the highest likelihood. A reasonable set of starting points can be chosen based on the observed data, e.g. using the method of moments estimator. Due to the increasingly complex likelihood surface, the number of optimization runs should increase with the number of parameters.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by <a href="https://www.oilbat.de" class="external-link">Lennart Oelschläger</a>, Timo Adam, Michels Rouven.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.1.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
